{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Zg1-CWwg5UJPCouv_STGjedVJAr4kdU9",
      "authorship_tag": "ABX9TyODYC1S02nFt0AqTQQRYMIo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aa05420/Coal-Mine-Warning-and-Monitoring-System/blob/main/ACGAN_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mxuAGstXi5l7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "# define the path to your data folders\n",
        "data_path = '/content/drive/MyDrive/MineData'\n",
        "images_haz_path = os.path.join(data_path, \"images_haz\")\n",
        "images_nonhaz_path = os.path.join(data_path, \"images_nonhaz\")\n",
        "\n",
        "# define the image size\n",
        "IMG_SIZE = 64\n",
        "\n",
        "# use ImageDataGenerator to load and preprocess the data\n",
        "datagen = ImageDataGenerator(rescale=1./255,\n",
        "                             validation_split=0.2)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(directory=data_path,\n",
        "                                              target_size=(IMG_SIZE, IMG_SIZE),\n",
        "                                              class_mode='binary',\n",
        "                                              batch_size=32,\n",
        "                                              subset='training')\n",
        "\n",
        "# normalize the images to the range [-1, 1]\n",
        "X_train = (train_generator.next()[0].astype(np.float32) - 0.5) * 2.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlQFpwjAlKBR",
        "outputId": "aff27391-02e1-46b6-8f51-9f73e1d6a4a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 798 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import keras\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, BatchNormalization, Activation, Embedding, multiply\n",
        "from keras.layers import UpSampling2D, Conv2D, LeakyReLU\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "data_path = '/content/drive/MyDrive/MineData'\n",
        "images_haz_path = os.path.join(data_path, \"images_haz\")\n",
        "images_nonhaz_path = os.path.join(data_path, \"images_nonhaz\")\n",
        "\n",
        "# Load and preprocess haz images\n",
        "haz_images = []\n",
        "for filename in os.listdir(images_haz_path):\n",
        "    img_path = os.path.join(images_haz_path, filename)\n",
        "    with Image.open(img_path) as img:\n",
        "        img = img.convert('L')  # convert to grayscale\n",
        "        img = img.resize((28, 28))\n",
        "        img = np.array(img)\n",
        "        img = (img.astype(np.float32) - 127.5) / 127.5  # normalize to [-1, 1]\n",
        "        haz_images.append(img)\n",
        "\n",
        "# Load and preprocess nonhaz images\n",
        "nonhaz_images = []\n",
        "for filename in os.listdir(images_nonhaz_path):\n",
        "    img_path = os.path.join(images_nonhaz_path, filename)\n",
        "    with Image.open(img_path) as img:\n",
        "        img = img.convert('L')  # convert to grayscale\n",
        "        img = img.resize((28, 28))\n",
        "        img = np.array(img)\n",
        "        img = (img.astype(np.float32) - 127.5) / 127.5  # normalize to [-1, 1]\n",
        "        nonhaz_images.append(img)\n",
        "\n",
        "\n",
        "# Combine haz and nonhaz images\n",
        "X_train = np.concatenate([np.array(haz_images), np.array(nonhaz_images)])\n",
        "\n",
        "# Create labels for haz and nonhaz images\n",
        "y_haz = np.zeros(len(haz_images))\n",
        "y_nonhaz = np.ones(len(nonhaz_images))\n",
        "y_train = np.concatenate([y_haz, y_nonhaz])\n",
        "\n",
        "# Shuffle the data\n",
        "shuffle_idxs = np.random.permutation(len(X_train))\n",
        "X_train = X_train[shuffle_idxs]\n",
        "y_train = y_train[shuffle_idxs]\n",
        "\n",
        "NUM_CLASSES = 2\n",
        "NUM_EPOCHS = 20\n",
        "BATCH_SIZE = 32\n",
        "BATCH_COUNT = math.ceil(X_train.shape[0] / BATCH_SIZE)\n",
        "NOISE_DIM = 100\n",
        "HALF_BATCH = int(BATCH_SIZE / 2)\n",
        "\n",
        "adam = Adam(lr=2e-4, beta_1=0.5)\n",
        "losses = ['binary_crossentropy', 'sparse_categorical_crossentropy']\n",
        "\n",
        "noise = Input(shape=(NOISE_DIM,))\n",
        "label = Input(shape=(1,), dtype='int32')\n",
        "label_embedding = Flatten()(Embedding(NUM_CLASSES, NOISE_DIM)(label))\n",
        "generator_input = multiply([noise, label_embedding])\n",
        "\n",
        "x = Dense(7 * 7 * 128)(generator_input)\n",
        "x = Reshape((7, 7, 128))(x)\n",
        "x = LeakyReLU(0.2)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = UpSampling2D()(x)\n",
        "x = Conv2D(64, kernel_size=(5, 5), padding='same')(x)\n",
        "x = LeakyReLU(0.2)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = UpSampling2D()(x)\n",
        "generator_output = Conv2D(1, kernel_size=(5, 5), padding='same', activation='tanh')(x)\n",
        "\n",
        "generator = Model([noise, label], generator_output)\n",
        "\n",
        "generator.compile(loss='binary_crossentropy', optimizer=adam)\n",
        "\n",
        "img = Input(shape=(28, 28, 1))\n",
        "x = Conv2D(64, kernel_size=(5, 5), strides=(2, 2), padding='same', input_shape=(28, 28, 3))(img)\n",
        "x = LeakyReLU(0.2)(x)\n",
        "x = Conv2D(128, kernel_size=(5, 5), strides=(2, 2), padding='same')(x)\n",
        "x = LeakyReLU(0.2)(x)\n",
        "x = Flatten()(x)\n",
        "validity = Dense(1, activation='sigmoid')(x)\n",
        "class_label = Dense(NUM_CLASSES + 1, activation='sigmoid')(x)\n",
        "# another class for fake class\n",
        "\n",
        "discriminator = Model(img, [validity, class_label])\n",
        "\n",
        "discriminator.compile(loss=losses, optimizer=adam)\n",
        "\n",
        "discriminator.trainable = False\n",
        "noise = Input(shape=(NOISE_DIM,))\n",
        "label = Input(shape=(1,), dtype='int32')\n",
        "generated_img = generator([noise, label])\n",
        "valid, target_label = discriminator(generated_img)\n",
        "combined = Model([noise, label], [valid, target_label])\n",
        "combined.compile(loss=losses, optimizer=adam)\n",
        "\n",
        "def save_imgs(epoch, num_examples=100):\n",
        "    noise = np.random.normal(0, 1, size=[num_examples, NOISE_DIM])\n",
        "    sampled_labels = np.random.randint(0, 2, num_examples).reshape(-1, 1)\n",
        "\n",
        "    generated_imgs = generator.predict([noise, sampled_labels])\n",
        "    generated_imgs = generated_imgs.reshape(num_examples, 28, 28)\n",
        "    for i in range(num_examples):\n",
        "        \n",
        "    # plt.figure(figsize=(10,10))\n",
        "        filename = '/content/drive/MyDrive/images/generated_image_epoch_{0}_index_{1}.png'.format(epoch+1, i+1)\n",
        "        img = Image.fromarray((generated_imgs[i] * 255).astype(np.uint8))\n",
        "        img.save(filename)\n",
        "    #     plt.subplot( 10, 10, i+1)\n",
        "    #     plt.imshow(generated_imgs[i], interpolation='nearest', cmap='gray')\n",
        "    #     plt.axis('off')\n",
        "    # plt.tight_layout()\n",
        "    # plt.savefig('/content/drive/MyDrive/images/acgan_generated_image_epoch_{0}.png'.format(epoch + 1))\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_d_loss = 0.\n",
        "    epoch_g_loss = 0.\n",
        "\n",
        "    for step in range(BATCH_COUNT):\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        # randomly select half a batch of real images\n",
        "        idx = np.random.randint(0, X_train.shape[0], HALF_BATCH)\n",
        "        imgs = X_train[idx]\n",
        "\n",
        "        # generate half a batch of fake images\n",
        "        noise = np.random.normal(0, 1, (HALF_BATCH, NOISE_DIM))\n",
        "        sampled_labels = np.random.randint(0, 2, HALF_BATCH).reshape(-1)\n",
        "        generated_imgs = generator.predict([noise, sampled_labels])\n",
        "\n",
        "        # use one-sided label smoothing\n",
        "        real_valid_y = np.ones((HALF_BATCH, 1)) * 0.9\n",
        "        fake_valid_y = np.zeros((HALF_BATCH, 1))\n",
        "\n",
        "        real_class_labels = y_train[idx]\n",
        "        # real classes are [0, NUM_CLASSES-1]\n",
        "        fake_class_labels = NUM_CLASSES * np.ones(HALF_BATCH).reshape(-1)\n",
        "\n",
        "        # train on real and fake images\n",
        "        d_loss_real = discriminator.train_on_batch(imgs, [real_valid_y, real_class_labels])\n",
        "        d_loss_fake = discriminator.train_on_batch(generated_imgs, [fake_valid_y, fake_class_labels])\n",
        "        # use combined loss\n",
        "        d_loss = 0.5 * (np.array(d_loss_real) + np.array(d_loss_fake))\n",
        "\n",
        "        epoch_d_loss += np.mean(d_loss)\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Generator\n",
        "        # ---------------------\n",
        "        noise = np.random.normal(0, 1, (BATCH_SIZE, NOISE_DIM))\n",
        "        real_valid_y = np.ones((BATCH_SIZE, 1))\n",
        "        sampled_labels = np.random.randint(0, 2, BATCH_SIZE).reshape(-1)\n",
        "        g_loss = combined.train_on_batch([noise, sampled_labels], [real_valid_y, sampled_labels])\n",
        "\n",
        "        # fold loss into cumulative moving average\n",
        "        # # use combined loss\n",
        "        epoch_g_loss += np.mean(g_loss)\n",
        "\n",
        "    print(\"%d [D loss: %f] [G loss: %f]\" % ((epoch + 1), epoch_d_loss / BATCH_COUNT, epoch_g_loss / BATCH_COUNT))\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        generator.save('/content/drive/MyDrive/models/acgan_generator_{0}.h5'.format(epoch + 1))\n",
        "        save_imgs(epoch)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "76p1Wi0jmUC1",
        "outputId": "0acca39b-c97c-4b9e-f472-6e25d9dffe19"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0a54f55bba9c>\u001b[0m in \u001b[0;36m<cell line: 104>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0mgenerated_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m \u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    278\u001b[0m                     \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 }:\n\u001b[0;32m--> 280\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    281\u001b[0m                         \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                         \u001b[0;34mf\"incompatible with the layer: expected axis {axis} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"model_1\" (type Functional).\n\nInput 0 of layer \"dense_2\" is incompatible with the layer: expected axis -1 of input shape to have value 401408, but received input with shape (None, 6272)\n\nCall arguments received by layer \"model_1\" (type Functional):\n  • inputs=tf.Tensor(shape=(None, 28, 28, 1), dtype=float32)\n  • training=None\n  • mask=None"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zRR5GNHlzDzA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}